cm = table(test_set[, 1], y_pred)
cm
ggplot(training_set, aes(x=Age, y=Survived)) + geom_point() +
stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)
ggplot(training_set, aes(x=Fare, y=Purchased)) + geom_point() +
stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)
ggplot(training_set, aes(x=Fare, y=Survived)) + geom_point() +
stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)
ggplot(test_set, aes(x=Fare, y=Survived)) + geom_point() +
stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)
ggplot(test_set, aes(x=Age, y=Survived)) + geom_point() +
stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set) - 1, max(set) + 1, by = 0.01)
X2 = seq(min(set) - 1, max(set) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set) - 1, max(set) + 1, by = 0.01)
X2 = seq(min(set) - 1, max(set) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 100]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 220]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
X1 = seq( - 1,  + 1, by = 0.01)
X2 = seq( - 1,  + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
X1 = seq( - 1,  + 1, by = 0.01)
X2 = seq( - 1,  + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 100]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 220]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 100]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 220]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
colnames(grid_set) = c('Fare', 'Survived')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
head(datasetPractice)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Survived', 'Fare')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
colnames(grid_set) = c('Survived', 'Fare', 'Age')
colnames(grid_set) = c('Fare', 'Age')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
getwd()
setwd("/Users/fernando/Documents/mineria/mineria_datos/Unidad2/Practicas/Practica1")
getwd()
# Importing the dataset
datasetPractice <- read.csv('data.csv')
datasetPractice <- datasetPractice[ -c(1,4,7:9,11,12) ]
head(datasetPractice)
# Splitting the dataset into the Training set and Test set
# Install.packages('caTools')
library(caTools)
set.seed(123)
split <- sample.split(datasetPractice$Survived, SplitRatio = 0.75)
training_set <- subset(datasetPractice, split == TRUE)
test_set <- subset(datasetPractice, split == FALSE)
# Feature scaling
training_set[, 4:5] <- scale(training_set[, 4:5])
test_set[, 4:5] <- scale(test_set[, 4:5])
?glm
# Fitting Logistic Regression to Training set
classifier = glm(formula = Survived ~ Age + Fare,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set[-3])
prob_pred
y_pred = ifelse(prob_pred > 0.5, 1, 0)
y_pred
# Making the Confusion Metrix
cm = table(test_set[, 1], y_pred)
cm
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Fare', 'Age')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Survived',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Fare', 'Age')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Fare', ylab = 'Age',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Fare', 'Age')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Fare', ylab = 'Age',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 1] == 1, 'green4', 'red3'))
View(test_set)
datasetPractice[is.na(x = datasetPractice$Age)] <- 0
datasetPractice[is.na(datasetPractice$Age = "NA")] <- 0
datasetPractice$Age[is.na(datasetPractice$Age)] <- 0
getwd()
setwd("/Users/fernando/Documents/mineria/mineria_datos/Unidad2/Practicas/Practica1")
getwd()
# Importing the dataset
datasetPractice <- read.csv('data.csv')
datasetPractice <- datasetPractice[ -c(1,4,7:9,11,12) ]
datasetPractice$Age[is.na(datasetPractice$Age)] <- 0
library(caTools)
set.seed(123)
split <- sample.split(datasetPractice$Survived, SplitRatio = 0.75)
training_set <- subset(datasetPractice, split == TRUE)
test_set <- subset(datasetPractice, split == FALSE)
View(test_set)
training_set[, 4:5] <- scale(training_set[, 4:5])
test_set[, 4:5] <- scale(test_set[, 4:5])
classifier = glm(formula = Survived ~ Age + Fare,
family = binomial,
data = training_set)
View(classifier)
prob_pred = predict(classifier, type = 'response', newdata = test_set[-1])
prob_pred
y_pred = ifelse(prob_pred > 0.5, 1, 0)
y_pred
cm = table(test_set[, 1], y_pred)
cm
ggplot(training_set, aes(x=Age, y=Survived)) + geom_point() +
stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Fare', 'Age')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Fare', ylab = 'Age',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 1] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'fare')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Fare',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 1] == 1, 'green4', 'red3'))
View(test_set)
getwd()
setwd("/Users/fernando/Documents/mineria/mineria_datos/Unidad2/Practicas/Practica1")
getwd()
# Importing the dataset
dataset <- read.csv('Social_Network_Ads.csv')
dataset <- dataset[, 3:5]
# Splitting the dataset into the Training set and Test set
# Install.packages('caTools')
library(caTools)
set.seed(123)
split <- sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set <- subset(dataset, split == TRUE)
test_set <- subset(dataset, split == FALSE)
# Feature scaling
training_set[, 1:2] <- scale(training_set[, 1:2])
test_set[, 1:2] <- scale(test_set[, 1:2])
# Fitting Logistic Regression to Training set
classifier = glm(formula = Purchased ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set[-3])
prob_pred
y_pred = ifelse(prob_pred > 0.5, 1, 0)
y_pred
# Making the Confusion Metrix
cm = table(test_set[, 3], y_pred)
cm
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
View(training_set)
training_set[, 4:5] <- scale(training_set[, 4:5])
getwd()
setwd("/Users/fernando/Documents/mineria/mineria_datos/Unidad2/Practicas/Practica1")
getwd()
# Importing the dataset
datasetPractice <- read.csv('data.csv')
datasetPractice <- datasetPractice[ -c(1,4,7:9,11,12) ]
#Delete NA data
datasetPractice$Age[is.na(datasetPractice$Age)] <- 0
head(datasetPractice)
# Splitting the dataset into the Training set and Test set
# Install.packages('caTools')
library(caTools)
set.seed(123)
split <- sample.split(datasetPractice$Survived, SplitRatio = 0.75)
training_set <- subset(datasetPractice, split == TRUE)
test_set <- subset(datasetPractice, split == FALSE)
training_set[, 4:5] <- scale(training_set[, 4:5])
View(training_set)
set = training_set
X1 = seq(min(set[, 4]) - 1, max(set[, 4]) + 1, by = 0.01)
X2 = seq(min(set[, 5]) - 1, max(set[, 5]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'fare')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Fare',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 1] == 1, 'green4', 'red3'))
getwd()
setwd("/Users/fernando/Documents/mineria/mineria_datos/Unidad2/Practicas/Practica1")
getwd()
# Importing the dataset
datasetPractice <- read.csv('data.csv')
datasetPractice <- datasetPractice[ -c(1,4,7:9,11,12) ]
#Delete NA data
datasetPractice$Age[is.na(datasetPractice$Age)] <- 0
head(datasetPractice)
# Splitting the dataset into the Training set and Test set
# Install.packages('caTools')
library(caTools)
set.seed(123)
split <- sample.split(datasetPractice$Survived, SplitRatio = 0.75)
training_set <- subset(datasetPractice, split == TRUE)
test_set <- subset(datasetPractice, split == FALSE)
# Feature scaling
training_set[, 4:5] <- scale(training_set[, 4:5])
test_set[, 4:5] <- scale(test_set[, 4:5])
?glm
# Fitting Logistic Regression to Training set
classifier = glm(formula = Survived ~ Age + Fare,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set[-1])
prob_pred
y_pred = ifelse(prob_pred > 0.5, 1, 0)
y_pred
# Making the Confusion Metrix
cm = table(test_set[, 1], y_pred)
cm
getwd()
setwd("/Users/fernando/Documents/mineria/mineria_datos/Unidad2/Practicas/Practica1")
getwd()
# Importing the dataset
datasetPractice <- read.csv('data.csv')
datasetPractice <- datasetPractice[ -c(1,4,7:9,11,12) ]
#Delete NA data
datasetPractice$Age[is.na(datasetPractice$Age)] <- 0
head(datasetPractice)
# Splitting the dataset into the Training set and Test set
# Install.packages('caTools')
library(caTools)
set.seed(123)
split <- sample.split(datasetPractice$Survived, SplitRatio = 0.75)
training_set <- subset(datasetPractice, split == TRUE)
test_set <- subset(datasetPractice, split == FALSE)
# Feature scaling
training_set[, 4:5] <- scale(training_set[, 4:5])
test_set[, 4:5] <- scale(test_set[, 4:5])
?glm
# Fitting Logistic Regression to Training set
classifier = glm(formula = Survived ~ Age + Fare,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set[-1])
prob_pred
y_pred = ifelse(prob_pred > 0.5, 1, 0)
y_pred
# Making the Confusion Metrix
cm = table(test_set[, 1], y_pred)
cm
set = training_set
X1 = seq(min(set[, 4]) - 1, max(set[, 4]) + 1, by = 0.01)
X2 = seq(min(set[, 5]) - 1, max(set[, 5]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'fare')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Fare',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 1] == 1, 'green4', 'red3'))
X1 = seq(min(set[, 4]) - 1, max(set[, 4]) + 1, by = 0.01)
X2 = seq(min(set[, 5]) - 1, max(set[, 5]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'fare')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Fare',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 1] == 1, 'green4', 'red3'))
X2 = seq(min(set[, 5]) - 1, max(set[, 5]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'fare')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Fare',
xlim = range(X1), ylim = range(X2))
plot(set[, -1],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Fare',
xlim = range(X1), ylim = range(X2))
